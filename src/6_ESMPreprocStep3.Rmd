# This Rmarkdown is based on the step-by-step guidelines for preprocessing ESM data provided by Revol et al., (2024) via their website: https://preprocess.esmtools.com/, and contains code from or adapted from "Step 3: Participants Response Behaviors". 

#Load necessary packages
```{r}
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)
```

#Read in data
```{r}
file_path <- "C:/Users/Walt/OneDrive - The Pennsylvania State University/Projects/ASH/DVAL/Users/Walter/Preprocessing/Interim Data/EMA_and_baseline2.rds"
d <- readRDS(file_path)
```

#Create latency_mins variable (start/end difference in minutes)
```{r}
d <- d %>%
  mutate(
    init_time = as.POSIXct(init_time),
    time_submit = as.POSIXct(completion_time),
    latency_mins = as.numeric(difftime(completion_time, init_time, units = "mins"))
  )
```

#Survey completion latency outliers across all participants
```{r}
# Step 1: Calculate global mean and standard deviation of latency
latency_mean <- mean(d$latency_mins, na.rm = TRUE)
latency_sd <- sd(d$latency_mins, na.rm = TRUE)

# Step 2: Compute z-scores and flag outliers beyond ±3 SD
d <- d %>%
  mutate(
    latency_z = (latency_mins - latency_mean) / latency_sd,
    latency_outlier_global = abs(latency_z) > 3  # ±3 SD threshold
  )

# Step 3: Examine results
# Count of global outliers
print(table(d$latency_outlier_global, useNA = "ifany"))

# Summary of raw latency values and z-scores
print(summary(d$latency_mins))
print(summary(d$latency_z))

# View outlier rows
outliers_df <- d %>%
  filter(latency_outlier_global == TRUE) %>%
  select(participant_id, latency_mins, latency_z, init_time, completion_time)

print(outliers_df)

# Step 4: Plot histogram using raw latency values with vertical lines at ±3 SD
upper_bound <- latency_mean + 3 * latency_sd
lower_bound <- latency_mean - 3 * latency_sd

ggplot(d, aes(x = latency_mins)) +
  geom_histogram(bins = 50, fill = "lightblue", color = "black", na.rm = TRUE) +
  geom_vline(xintercept = c(lower_bound, upper_bound), linetype = "dashed", color = "red", size = 1) +
  labs(
    title = "Histogram of Survey Completion Latency with ±3 SD Outlier Bounds",
    x = "Latency (minutes)",
    y = "Count"
  ) +
  theme_minimal()
```

#Survey completion latency outliers within participants
```{r}
# Compute z-scores within each participant and flag outliers
d <- d %>%
  group_by(participant_id) %>%
  mutate(
    latency_mean = mean(latency_mins, na.rm = TRUE),
    latency_sd = sd(latency_mins, na.rm = TRUE),
    latency_z_within = (latency_mins - latency_mean) / latency_sd,
    latency_outlier_within = abs(latency_z_within) > 2  # Flag > 2 SD from person's own mean
  ) %>%
  ungroup()

# Examine: Count of within-person outliers
print(table(d$latency_outlier_within, useNA = "ifany"))

# Proportion of outliers per participant
d %>%
  group_by(participant_id) %>%
  summarise(
    n_surveys = n(),
    n_outliers = sum(latency_outlier_within, na.rm = TRUE),
    prop_outliers = n_outliers / n_surveys
  ) %>%
  arrange(desc(prop_outliers))
```

#Examine data from participants (PIDs 128, 104, 163, and 164) with a high proportion (arbtrarily defined as >0.080) of outliers
```{r}
# Filter for the selected participants
target_participants <- c(128, 104, 163, 164)

d_subset <- d %>%
  filter(participant_id %in% target_participants)

# Plot: Histogram of latency_mins by participant
ggplot(d_subset, aes(x = latency_mins)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", na.rm = TRUE) +
  facet_wrap(~ participant_id, scales = "free_y") +
  labs(
    title = "Histogram of Survey Completion Times (latency_mins)",
    x = "Latency (minutes)",
    y = "Count"
  ) +
  theme_minimal()
```
#Examine data from participants who submitted at least one survey after 15 minutes (arbitrarily selected)
```{r}
# Step 1: Calculate global mean and SD of latency
latency_mean <- mean(d$latency_mins, na.rm = TRUE)
latency_sd <- sd(d$latency_mins, na.rm = TRUE)

# Step 2: Calculate lower and upper bounds at ±3 SD
lower_bound <- latency_mean - 3 * latency_sd
upper_bound <- latency_mean + 3 * latency_sd

# Step 3: Identify participants with latency_mins outside ±3 SD
participants_outliers <- d %>%
  filter(latency_mins <= lower_bound | latency_mins >= upper_bound) %>%
  distinct(participant_id)
library(ggplot2)
library(dplyr)

# Extract participant IDs from participants_outliers (assuming it's a tibble with participant_id)
outlier_ids <- participants_outliers$participant_id

# Filter data for just those participants
d_outliers <- d %>%
  filter(participant_id %in% outlier_ids)

# Plot histogram faceted by participant
ggplot(d_outliers, aes(x = latency_mins)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", na.rm = TRUE) +
  facet_wrap(~ participant_id, scales = "free_y") +
  labs(
    title = "Latency Minutes Histogram for Participants with ±3 SD Outliers",
    x = "Latency (minutes)",
    y = "Count"
  ) +
  theme_minimal()
```
#Interpretation: 383 may be considered careless responding (6/22/25)
#Compliance rate 
```{r}
#Examine occurrences of "opted-out" responses for each participant across key DVAL outcome: mood (values from beeps where participants opted out were coded as "999" in EMA preprocessing, 2_ and 3_).
d %>%
  filter(mood == 999) %>%
  group_by(participant_id) %>%
  summarise(freq_999 = n()) %>%
  arrange(desc(freq_999))
```
#The following section uses the 'valid' variable, which is created based on study aims. Currently (6/22/25), validity is defined as it was in RMDs 2_ and 3_: participants must have non-missing data for all three of the main model variables: easy_difficult, mood, and pleasant.
```{r}
#First, define validity as it was in previous RMDs
d$var_of_interest_valid = rowSums(!is.na(dplyr::select(d, easy_difficult, mood, pleasant)))
table(d$var_of_interest_valid)
```
#Interpretation: of the above: There are 1833 valid cases based on this definition of validity.

# Examine global distribution of valid cases across study days
```{r}
valid_distr_study_day <- d %>%
  filter(var_of_interest_valid == 3) %>%
  group_by(study_day) %>%
  summarise(count_3s = n(), .groups = "drop") %>%
  complete(study_day = 1:10, fill = list(count_3s = 0))
#Plot
ggplot(valid_distr_study_day, aes(x = factor(study_day), y = count_3s)) + 
  geom_bar(stat = "identity", fill = "darkorange") +
  labs(
    x = "Study Day",
    y = "Count of Value '3'",
    title = "Frequency of '3' in var_of_interest_valid by Study Day"
  ) +
  theme_minimal()
```
#Interpretation: Day 6 (part6 day 3) has the fewest available cases for main DVAL analyses.

# Examine total valid responses (== 3) per participant
```{r}
# Create compliance variable
obsno_max <- 60

# Calculate compliance: proportion of time var_of_interest_valid == 3
d$compliance <- ave(d$var_of_interest_valid == 3, d$participant_id, 
                    FUN = function(x) sum(x, na.rm = TRUE)) / obsno_max

# Bar plot of compliance per participant
d %>%
  group_by(participant_id) %>%
  slice(1) %>%  # one row per participant
  ggplot(aes(x = reorder(factor(participant_id), compliance), y = compliance)) +
  geom_col(fill = "steelblue") +
  labs(
    x = "Participant ID",
    y = "Compliance Rate (value == 3)",
    title = "Participant Compliance Based on var_of_interest_valid == 3"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
``` 

#Save updates to data
```{r}
saveRDS(d, "C:\\Users\\Walt\\OneDrive - The Pennsylvania State University\\Projects\\ASH\\DVAL\\Users\\Walter\\Preprocessing\\Interim Data\\EMA_and_baseline3.rds")
```

#References

#Revol, J., Carlier, C., Lafit, G., Verhees, M., Sels, L., & Ceulemans, E. (2024). Preprocessing ESM data: a step-by-step framework, tutorial website, R package, and reporting templates.